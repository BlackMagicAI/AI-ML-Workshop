{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xor_project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtedder/AI-ML-Workshop/blob/master/notebooks/xor_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2TvWRvDUb1uS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#XOR Keras Project\n",
        "\n",
        "[Ref Docs 1](https://blog.thoughtram.io/machine-learning/2016/11/02/understanding-XOR-with-keras-and-tensorlow.html)\n",
        "\n",
        "[Ref Docs 2](https://github.com/brianschardt/xor_keras_tensorflow_serving/blob/master/index.py)\n",
        "\n",
        "![alt text](https://image.slidesharecdn.com/electroniccircuits-090706070731-phpapp01/95/electronic-circuits-32-728.jpg?cb=1246864077)"
      ]
    },
    {
      "metadata": {
        "id": "81fIB24wcYnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Uncommet this code if you need colboratory tensorflow version to match the versions available in google Cloud ML. NOT required for this example\n",
        "#!pip install tensorflow==1.12.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJj5UnL4cApy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Imports"
      ]
    },
    {
      "metadata": {
        "id": "eI_l2LBAbsgM",
        "colab_type": "code",
        "outputId": "74268a92-89b4-4bca-c18f-d792a83f555c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "#from tensorflow import keras\n",
        "\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl, utils\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD #Stochastic gradient descent optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "b-tKmnxUcu1g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Version Info"
      ]
    },
    {
      "metadata": {
        "id": "Cehzl6o4c16W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python --version\n",
        "# print(\"Tensorflow version\" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yq5tkN92c75c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2. Data Preparation\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "esZB324AfN7d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Exhaustion of Different Possibilities\n",
        "X = np.array([\n",
        "    [0,0],\n",
        "    [0,1],\n",
        "    [1,0],\n",
        "    [1,1]\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrzO1bAUd8Uh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##3. Feature Extraction\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "effzeOaqc-7p",
        "colab_type": "code",
        "outputId": "155117d1-94e9-49e1-93bd-f814b5e313d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "#Create dataframe version of x (features) from np array\n",
        "x_df = pd.DataFrame({'x1':X[:,0],'x2':X[:,1]})\n",
        "print(x_df)\n",
        "\n",
        "#Return values of the different inputs\n",
        "Y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "#Create dataframe version of x (labels)\n",
        "y_df = pd.DataFrame({'y':Y[:,0]})\n",
        "print(y_df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2\n",
            "0   0   0\n",
            "1   0   1\n",
            "2   1   0\n",
            "3   1   1\n",
            "   y\n",
            "0  0\n",
            "1  1\n",
            "2  1\n",
            "3  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iVWAp-mNfVBa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##4. Build Model\n",
        "Ref:\n",
        "![Example Model](https://i.stack.imgur.com/S52yR.png)"
      ]
    },
    {
      "metadata": {
        "id": "Zivbp-N7eGy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ca622444-1dc3-46ea-8a46-d5a8ee61d7b9"
      },
      "cell_type": "code",
      "source": [
        "#https://www.tensorflow.org/api_docs/python/tf/metrics/accuracy\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/models\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential\n",
        "#Specify the type of layers to use Densely-connected layer class - https://www.tensorflow.org/api_docs/python/tf/layers/Dense\n",
        "#SGD - https://keras.io/optimizers/\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#compile\n",
        "#https://keras.io/backend/#using-the-abstract-keras-backend-to-write-new-code\n",
        "sess = tf.Session()\n",
        "from keras import backend as K\n",
        "K.set_session(sess)\n",
        "K.set_learning_phase(0) #all new operations will be in test mode from now on - The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time\n",
        "\n",
        "#Create XOR Model\n",
        "#Create Model\n",
        "#Model - groups layers into an object with training and inference features.\n",
        "#Sequential - Linear stack of layers.\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=2))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "sgd = SGD(lr=0.1)\n",
        "#binary_accuracy = the frequency with which predictions matches labels\n",
        "model.compile(loss='mse', optimizer=sgd, metrics=['binary_accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGq_jHwifoSd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##5. Train Model\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "89hKBrWjfqae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17491
        },
        "outputId": "7cdd2c2e-88ec-43f1-c23a-488b1370d28c"
      },
      "cell_type": "code",
      "source": [
        "#Call the model.fit function\n",
        "#Train using fit which Trains the model for a fixed number of epochs (iterations on a dataset) - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit\n",
        "epoch = 500 ## the higher this number is the more accurate the prediction will be 10000 is a good number to set it at just takes a while to train\n",
        "history = model.fit(x_df, y_df, batch_size=1, nb_epoch=epoch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 0s 103ms/step - loss: 0.2658 - binary_accuracy: 0.5000\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2651 - binary_accuracy: 0.5000\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2638 - binary_accuracy: 0.5000\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2628 - binary_accuracy: 0.5000\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2621 - binary_accuracy: 0.7500\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2610 - binary_accuracy: 0.7500\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2601 - binary_accuracy: 0.5000\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2589 - binary_accuracy: 0.5000\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2583 - binary_accuracy: 0.7500\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2574 - binary_accuracy: 0.5000\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2564 - binary_accuracy: 0.5000\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2559 - binary_accuracy: 0.7500\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2550 - binary_accuracy: 0.7500\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2541 - binary_accuracy: 0.7500\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2532 - binary_accuracy: 0.7500\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2523 - binary_accuracy: 0.5000\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2516 - binary_accuracy: 0.5000\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2509 - binary_accuracy: 0.7500\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2503 - binary_accuracy: 0.7500\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2497 - binary_accuracy: 0.7500\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2487 - binary_accuracy: 0.7500\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2479 - binary_accuracy: 0.7500\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2472 - binary_accuracy: 0.7500\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2466 - binary_accuracy: 0.5000\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2459 - binary_accuracy: 0.7500\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2452 - binary_accuracy: 0.2500\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2447 - binary_accuracy: 0.7500\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2441 - binary_accuracy: 0.7500\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2431 - binary_accuracy: 0.5000\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2428 - binary_accuracy: 0.7500\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2421 - binary_accuracy: 0.7500\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2411 - binary_accuracy: 0.5000\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2405 - binary_accuracy: 0.5000\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2399 - binary_accuracy: 0.7500\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2393 - binary_accuracy: 0.7500\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2385 - binary_accuracy: 0.5000\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2375 - binary_accuracy: 0.7500\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2372 - binary_accuracy: 0.7500\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2364 - binary_accuracy: 0.7500\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2356 - binary_accuracy: 0.7500\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2349 - binary_accuracy: 0.5000\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2340 - binary_accuracy: 0.7500\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2335 - binary_accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2325 - binary_accuracy: 0.7500\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2319 - binary_accuracy: 0.7500\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2310 - binary_accuracy: 0.7500\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2304 - binary_accuracy: 0.7500\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2296 - binary_accuracy: 0.7500\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2285 - binary_accuracy: 0.7500\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2281 - binary_accuracy: 0.5000\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2272 - binary_accuracy: 0.5000\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2264 - binary_accuracy: 0.5000\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2252 - binary_accuracy: 0.5000\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2247 - binary_accuracy: 0.5000\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2236 - binary_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2229 - binary_accuracy: 0.5000\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2221 - binary_accuracy: 0.5000\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2208 - binary_accuracy: 0.5000\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2202 - binary_accuracy: 0.7500\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2191 - binary_accuracy: 0.7500\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2181 - binary_accuracy: 0.7500\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2176 - binary_accuracy: 0.7500\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2162 - binary_accuracy: 0.7500\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2155 - binary_accuracy: 0.7500\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2145 - binary_accuracy: 0.7500\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2133 - binary_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2126 - binary_accuracy: 0.7500\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2114 - binary_accuracy: 0.7500\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2103 - binary_accuracy: 0.7500\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2094 - binary_accuracy: 0.7500\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2083 - binary_accuracy: 0.7500\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2073 - binary_accuracy: 0.7500\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2061 - binary_accuracy: 0.7500\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2051 - binary_accuracy: 0.7500\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2038 - binary_accuracy: 0.7500\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2029 - binary_accuracy: 0.7500\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2018 - binary_accuracy: 0.7500\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2007 - binary_accuracy: 0.7500\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1995 - binary_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1979 - binary_accuracy: 0.7500\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1972 - binary_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1959 - binary_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1946 - binary_accuracy: 0.7500\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1932 - binary_accuracy: 0.7500\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1919 - binary_accuracy: 0.7500\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1909 - binary_accuracy: 0.7500\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1895 - binary_accuracy: 0.7500\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1882 - binary_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1871 - binary_accuracy: 0.7500\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1859 - binary_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1845 - binary_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1832 - binary_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1820 - binary_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1806 - binary_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1792 - binary_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1779 - binary_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1765 - binary_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1750 - binary_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1738 - binary_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1724 - binary_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1710 - binary_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1693 - binary_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1682 - binary_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1668 - binary_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1650 - binary_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1640 - binary_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1625 - binary_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1610 - binary_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1596 - binary_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1580 - binary_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1564 - binary_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1552 - binary_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1537 - binary_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1521 - binary_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1507 - binary_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1492 - binary_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1477 - binary_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1463 - binary_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1447 - binary_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1432 - binary_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1417 - binary_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1400 - binary_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1385 - binary_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1372 - binary_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1357 - binary_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1342 - binary_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1327 - binary_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1312 - binary_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1297 - binary_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1282 - binary_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1266 - binary_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1250 - binary_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1238 - binary_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1223 - binary_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1208 - binary_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1193 - binary_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1177 - binary_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1162 - binary_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1149 - binary_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1133 - binary_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1121 - binary_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1107 - binary_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1094 - binary_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1078 - binary_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1051 - binary_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1037 - binary_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1023 - binary_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1011 - binary_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0996 - binary_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.0984 - binary_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0970 - binary_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0956 - binary_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0945 - binary_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0933 - binary_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0918 - binary_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0907 - binary_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0895 - binary_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0882 - binary_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0871 - binary_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0859 - binary_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0846 - binary_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0835 - binary_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0824 - binary_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0813 - binary_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0800 - binary_accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0790 - binary_accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0778 - binary_accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0757 - binary_accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0748 - binary_accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0738 - binary_accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0727 - binary_accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0717 - binary_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0707 - binary_accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0698 - binary_accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0688 - binary_accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0669 - binary_accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0660 - binary_accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0652 - binary_accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0643 - binary_accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0634 - binary_accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0625 - binary_accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0616 - binary_accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0609 - binary_accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0593 - binary_accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0584 - binary_accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0577 - binary_accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0569 - binary_accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0562 - binary_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0547 - binary_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0540 - binary_accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0533 - binary_accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0527 - binary_accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0519 - binary_accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0513 - binary_accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0506 - binary_accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0500 - binary_accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0494 - binary_accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0488 - binary_accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0481 - binary_accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0475 - binary_accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0469 - binary_accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0463 - binary_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0458 - binary_accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0452 - binary_accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0446 - binary_accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0441 - binary_accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0436 - binary_accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0431 - binary_accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0426 - binary_accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0421 - binary_accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0416 - binary_accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0410 - binary_accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0406 - binary_accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0401 - binary_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0396 - binary_accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0392 - binary_accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0387 - binary_accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0383 - binary_accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0379 - binary_accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0374 - binary_accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0370 - binary_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0366 - binary_accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0362 - binary_accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0358 - binary_accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0354 - binary_accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0350 - binary_accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0346 - binary_accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0343 - binary_accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0339 - binary_accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0335 - binary_accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0332 - binary_accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0328 - binary_accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0325 - binary_accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0321 - binary_accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0318 - binary_accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0315 - binary_accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0311 - binary_accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0308 - binary_accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0305 - binary_accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0302 - binary_accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0299 - binary_accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0296 - binary_accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0293 - binary_accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0290 - binary_accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0287 - binary_accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0284 - binary_accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0282 - binary_accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0279 - binary_accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0276 - binary_accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0274 - binary_accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0271 - binary_accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0268 - binary_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0266 - binary_accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0263 - binary_accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0261 - binary_accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0258 - binary_accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0256 - binary_accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0254 - binary_accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0251 - binary_accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0249 - binary_accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0247 - binary_accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0245 - binary_accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0242 - binary_accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0240 - binary_accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0238 - binary_accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0236 - binary_accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0234 - binary_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0232 - binary_accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0230 - binary_accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0228 - binary_accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0226 - binary_accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0224 - binary_accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0222 - binary_accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0220 - binary_accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0218 - binary_accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0217 - binary_accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0215 - binary_accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0213 - binary_accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0211 - binary_accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0210 - binary_accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0208 - binary_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0206 - binary_accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0205 - binary_accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0203 - binary_accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0201 - binary_accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0200 - binary_accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0198 - binary_accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0197 - binary_accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0195 - binary_accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0194 - binary_accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0192 - binary_accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0191 - binary_accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0189 - binary_accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0188 - binary_accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0186 - binary_accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0185 - binary_accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0183 - binary_accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0182 - binary_accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0181 - binary_accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0179 - binary_accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0178 - binary_accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0177 - binary_accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0176 - binary_accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0174 - binary_accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0173 - binary_accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0172 - binary_accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0171 - binary_accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0169 - binary_accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0167 - binary_accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0166 - binary_accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0165 - binary_accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0163 - binary_accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0162 - binary_accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0161 - binary_accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0160 - binary_accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0159 - binary_accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0158 - binary_accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0157 - binary_accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0156 - binary_accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0155 - binary_accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0154 - binary_accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0153 - binary_accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0152 - binary_accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0151 - binary_accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0150 - binary_accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0149 - binary_accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0148 - binary_accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0147 - binary_accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0146 - binary_accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0144 - binary_accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0143 - binary_accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0142 - binary_accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0141 - binary_accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0141 - binary_accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0139 - binary_accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0138 - binary_accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0137 - binary_accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0136 - binary_accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0135 - binary_accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0135 - binary_accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0134 - binary_accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0133 - binary_accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0132 - binary_accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0130 - binary_accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0129 - binary_accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0128 - binary_accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0128 - binary_accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0127 - binary_accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0126 - binary_accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0125 - binary_accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0125 - binary_accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0124 - binary_accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0123 - binary_accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0123 - binary_accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0122 - binary_accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0121 - binary_accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0121 - binary_accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0120 - binary_accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0119 - binary_accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0119 - binary_accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0118 - binary_accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0117 - binary_accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0117 - binary_accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0116 - binary_accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0115 - binary_accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0115 - binary_accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0114 - binary_accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0113 - binary_accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0113 - binary_accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0111 - binary_accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0111 - binary_accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0110 - binary_accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0109 - binary_accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0109 - binary_accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0107 - binary_accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0107 - binary_accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0106 - binary_accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0106 - binary_accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0105 - binary_accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0104 - binary_accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0104 - binary_accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0103 - binary_accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0103 - binary_accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0102 - binary_accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0102 - binary_accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0101 - binary_accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0101 - binary_accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0100 - binary_accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0100 - binary_accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0098 - binary_accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0098 - binary_accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0098 - binary_accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0097 - binary_accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0097 - binary_accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0096 - binary_accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0096 - binary_accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0095 - binary_accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0095 - binary_accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0094 - binary_accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0094 - binary_accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0092 - binary_accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0092 - binary_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0091 - binary_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0091 - binary_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0091 - binary_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0090 - binary_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0090 - binary_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0089 - binary_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0089 - binary_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0089 - binary_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0087 - binary_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0087 - binary_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0087 - binary_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0086 - binary_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0086 - binary_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0084 - binary_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0084 - binary_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0084 - binary_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0083 - binary_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0083 - binary_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0083 - binary_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0082 - binary_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0082 - binary_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0082 - binary_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0080 - binary_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0080 - binary_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0080 - binary_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0079 - binary_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0079 - binary_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0079 - binary_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0077 - binary_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0077 - binary_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0077 - binary_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0075 - binary_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0075 - binary_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0075 - binary_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0073 - binary_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0073 - binary_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0073 - binary_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0071 - binary_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0071 - binary_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0071 - binary_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0071 - binary_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0069 - binary_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0069 - binary_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0069 - binary_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0069 - binary_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R18tpcbsgF8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##6. Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "F7VQSJ6YgH6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "33f18dd0-246f-40a3-fff3-c0394e23b696"
      },
      "cell_type": "code",
      "source": [
        "#Visualize the model's training progress\n",
        "#History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable)\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary_accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006776</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006752</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006728</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006704</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006680</td>\n",
              "      <td>499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     binary_accuracy      loss  epoch\n",
              "495              1.0  0.006776    495\n",
              "496              1.0  0.006752    496\n",
              "497              1.0  0.006728    497\n",
              "498              1.0  0.006704    498\n",
              "499              1.0  0.006680    499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "nmOsn_v-hKQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "4a67a154-1cf8-40e6-c3c8-9afe95180a94"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Is this model good? Visualize model performance,\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Abs Error [Out]')\n",
        "\n",
        "plt.plot(hist['epoch'], hist['loss'], label='Loss')\n",
        "\n",
        "plt.plot(hist['epoch'], hist['binary_accuracy'], label = 'binary_accuracy')\n",
        "plt.legend()\n",
        "plt.ylim([0,1.25])\n",
        "\n",
        "\"#Test model using the test data and evaluate\\n\",\n",
        "\"#Returns the loss value & metrics values for the model in test mode - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#evaluate\\n\",\n",
        "print(model.metrics_names)\n",
        "loss, ba = model.evaluate(x_df, y_df, verbose=0)\n",
        "print(\"Testing Loss/Error: {:5.2f} Out\".format(loss))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'binary_accuracy']\n",
            "Testing Loss/Error:  0.01 Out\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dSIuhdr4hfD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##7. Inference – Make Predictions"
      ]
    },
    {
      "metadata": {
        "id": "52qrfoj1hlhK",
        "colab_type": "code",
        "outputId": "37a094c1-019c-41a3-8a10-b7ca30665167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#Skip this step for model serving\n",
        "#Use test data to make predictions on trained model\n",
        "#Predict Generates output predictions for the input sample - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#predict\n",
        "#Then flatten numpy array result - https://www.tutorialspoint.com/numpy/numpy_ndarray_flatten.htm\n",
        "test_df = pd.DataFrame({'x1':[0.0,0.0, 1.0, 1.0],'x2':[0.0,1.0, 0.0, 1.0]})\n",
        "print ('Results of Model', model.predict(test_df).round())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of Model [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQGBSU5fjcEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deploy to ML Cloud Engine"
      ]
    },
    {
      "metadata": {
        "id": "IyEilxxHjkMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##8. Prepare Model for Saving"
      ]
    },
    {
      "metadata": {
        "id": "EE-5uYwUNXWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d53346ad-e5ab-464d-fa3a-1b9af4947319"
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf 1\n",
        "model.input\n",
        "model.output"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'activation_2/Sigmoid:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "DYl0OilzjhHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "d5de307c-c3fc-4079-e435-3e66a7cf3562"
      },
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "#https://www.tensorflow.org/guide/low_level_intro\n",
        "model_version = \"1\" #Change this to export different model versions, i.e. 2, ..., 7\n",
        "\n",
        "#setting values for the sake of saving the model in the proper format\n",
        "# http://amygdala.github.io/ml/tensorflow/cloud_ml_engine/2018/01/26/tf.html\n",
        "x = model.input\n",
        "y = model.output\n",
        "\n",
        "prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def({\"inputs\":x}, {\"prediction\":y}) #for XOR model\n",
        "\n",
        "# valid_prediction_signature = tf.saved_model.signature_def_utils.is_valid_signature(prediction_signature)\n",
        "# if(valid_prediction_signature == False):\n",
        "#     raise ValueError(\"Error: Prediction signature not valid!\")\n",
        "\n",
        "builder = saved_model_builder.SavedModelBuilder('./'+ model_version)\n",
        "#legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "#legacy_init_op = tf.group(tf.global_variables_initializer(), name='legacy_init_op')\n",
        "#legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "\n",
        "#Add the meta_graph and the variables to the builder\n",
        "#RefL https://www.tensorflow.org/api_docs/python/tf/saved_model/Builder#add_meta_graph\n",
        "#https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/saved_model/main_op\n",
        "builder.add_meta_graph_and_variables(\n",
        "      sess, [tag_constants.SERVING],\n",
        "      signature_def_map={\n",
        "           signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature,\n",
        "      },\n",
        "      main_op=tf.tables_initializer())\n",
        "      #legacy_init_op=legacy_init_op)\n",
        "\n",
        "# save the graph\n",
        "builder.save()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./1/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'./1/saved_model.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "QQZq7Iihkmna",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##9. Upload model to existing GCS bucket"
      ]
    },
    {
      "metadata": {
        "id": "2iUCrvgJkofZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebooks/io.ipynb#scrollTo=xM70QWdxeE7q\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Existing bucket name\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = ''  #INSERT YOUR BUCKET NAME HERE!!\n",
        "\n",
        "# Copy the model directory to our new bucket.\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!gsutil cp -r 1/. gs://{bucket_name}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8QwgebJlWSa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Upload GOOGLE_APPLICATION_CREDENTIALS\n"
      ]
    },
    {
      "metadata": {
        "id": "h4v_y0zWlXcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Upload GOOGLE_APPLICATION_CREDENTIALS json file from local computer and save to this notebook\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvuaiQutlieW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Set GOOGLE_APPLICATION_CREDENTIALS environment variable"
      ]
    },
    {
      "metadata": {
        "id": "kBJlnOKnljeX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '' #INSERT YOUR CREDENTIALS FILENAME HERE!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHe2eUNhl6AW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##10. Request online prediction from deployed model"
      ]
    },
    {
      "metadata": {
        "id": "J1I06jxFl87i",
        "colab_type": "code",
        "outputId": "00ca70dd-16c2-4500-f35d-6e5e0269b0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import googleapiclient \n",
        "from googleapiclient import discovery\n",
        "from googleapiclient import errors\n",
        "\n",
        "#Setup online cloud model\n",
        "#https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions\n",
        "#https://cloud.google.com/ml-engine/docs/v1/predict-request\n",
        "# https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library\n",
        "#https://www.raspberrypi.org/magpi/tensorflow-ai-raspberry-pi/\n",
        "#https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.98614&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
        "#https://stackoverflow.com/questions/45705070/how-to-load-and-use-a-saved-model-on-tensorflo\n",
        "\n",
        "\n",
        "# Create the ML Engine service object.\n",
        "# To authenticate set the environment variable\n",
        "# GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
        "#name = 'projects/{}/models/{}'.format(Project ID,  MODEL_NAME)\n",
        "service = googleapiclient.discovery.build('ml', 'v1')\n",
        "name = 'projects/{}/models/{}'.format(Project ID,  MODEL_NAME) #INSERT YOUR PROJECT ID AND NAME HERE!!\n",
        "\n",
        "#if version is not None:\n",
        "name += '/versions/{}'.format(MODEL_VERSION_NAME) #INSERT YOUR MODEL VERSION NAME HERE!!\n",
        "#name += '/versions/{}'.format('XOR_Version_1')\n",
        " \n",
        "print(name)\n",
        "\n",
        "response = service.projects().predict(\n",
        "    name=name,    \n",
        "    body={\"instances\": [{\"inputs\": [1.0,1.0]}, {\"inputs\": [0.0,0.0]}, {\"inputs\": [1.0,0.0]}]} #this WORKS! with the XOR model\n",
        ").execute()\n",
        "\n",
        "# if 'error' in response:\n",
        "#     raise RuntimeError(response['error'])\n",
        "response\n",
        "#np.round(response['predictions'][0]['prediction'])\n",
        "#response['predictions'][0]['prediction']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projects/mltest-229502/models/MpgModel/versions/XORV1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predictions': [{'prediction': [0.014323404990136623]},\n",
              "  {'prediction': [0.004028792958706617]},\n",
              "  {'prediction': [0.9865555763244629]}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}