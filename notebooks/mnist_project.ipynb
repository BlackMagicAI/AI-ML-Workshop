{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtedder/AI-ML-Workshop/blob/master/notebooks/mnist_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eIGOQ2JbCfAa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MNIST Keras Project\n",
        "\n",
        "[Ref 1](https://www.kaggle.com/yufengg/emnist-gpu-keras-to-tf)\n",
        "\n",
        "[Ref 2](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#1)\n",
        "\n",
        "[Ref 3](https://github.com/tensorflow/models/tree/master/official/mnist)\n",
        "\n",
        "[Image Classification\n",
        "](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d)\n",
        "\n",
        "[Keras Blog Example](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html#exporting-a-model-with-tensorflow-serving)\n",
        "\n",
        "[emnist GPU keras to TF](https://www.kaggle.com/yufengg/emnist-gpu-keras-to-tf/notebook)\n",
        "\n",
        "[Object detection](https://towardsdatascience.com/is-google-tensorflow-object-detection-api-the-easiest-way-to-implement-image-recognition-a8bd1f500ea0)\n",
        "\n",
        "[Object detection](https://www.edureka.co/blog/tensorflow-object-detection-tutorial/)\n",
        "\n",
        "[Computer vision](https://towardsdatascience.com/how-to-do-everything-in-computer-vision-2b442c469928)"
      ]
    },
    {
      "metadata": {
        "id": "FYlfJS8LCcZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Uncommet this code if you need colboratory tensorflow version to match the versions available in google Cloud ML\n",
        "#THIS IS REQUIRED\n",
        "#!pip install tensorflow==1.12.0\n",
        "# !sudo pip install tensorflow==1.11 #Raspberry pi version\n",
        "#!pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMdgBHS3MF9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf 1\n",
        "# !rm -rf estimator_model export model1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uKTseZBICsdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ]
    },
    {
      "metadata": {
        "id": "XiJ1RtYbEYg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# sess = tf.Session()\n",
        "\n",
        "from tensorflow import keras\n",
        "# from keras import backend as K\n",
        "\n",
        "# K.set_session(sess)\n",
        "# K.set_learning_phase(0) # all new operations will be in test mode from now on\n",
        "\n",
        "# from functools import partial\n",
        "# from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "# from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl, utils\n",
        "\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "#import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpATwMDqC4E9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Version Info"
      ]
    },
    {
      "metadata": {
        "id": "Mwr9R0dTC8Va",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Keras version \" + keras.__version__)\n",
        "print(\"Tensorflow version\" + tf.__version__)\n",
        "# !python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EKaL86KDAW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data Preparation\n",
        "\n",
        "Also available from: (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "[Original Dataset](https://www.nist.gov/node/1298471/emnist-dataset)"
      ]
    },
    {
      "metadata": {
        "id": "Q0wuVEWRn9Yl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Optional datasets"
      ]
    },
    {
      "metadata": {
        "id": "bOuyrkV6k1F-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download full emnist dataset\n",
        "# !wget http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
        "# Unzip to new directory - suppress zipfile directory name\n",
        "# !unzip -j gzip.zip -d mnist_datasets\n",
        "# Unzip desired gz files\n",
        "# !gzip -d mnist_datasets/emnist-digits-train-images-idx3-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sf-lirueFBAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_path = '../content/sample_data/mnist_train_small.csv'\n",
        "test_data_path = '../content/sample_data/mnist_test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path, header=None)\n",
        "test_data = pd.read_csv(test_data_path, header=None)\n",
        "\n",
        "train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OK2KJKyDFsg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "zpF_V9NkFu9e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "zs1Lkv_hFxpX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(data, row_num):\n",
        "    img_flip = np.transpose(data.values[row_num,1:].reshape(28, 28), axes=[1,0]) # img_size * img_size arrays\n",
        "    plt.title('Class: ' + str(data.values[row_num,0]) + ', Label: ' + str(class_mapping[data.values[row_num,0]]))\n",
        "    plt.imshow(data.values[row_num, 1:].reshape([28, 28]), cmap='Greys_r')\n",
        "    \n",
        "# 10 digits, 26 letters, and 11 capital letters that are different looking from their lowercase counterparts\n",
        "num_classes = 10 \n",
        "img_size = 28\n",
        "\n",
        "def img_label_load(data_path, num_classes=None):\n",
        "    data = pd.read_csv(data_path, header=None)\n",
        "    data_rows = len(data)\n",
        "    if not num_classes:\n",
        "        num_classes = len(data[0].unique())\n",
        "    \n",
        "    # this assumes square imgs. Should be 28x28\n",
        "    img_size = int(np.sqrt(len(data.iloc[0][1:])))\n",
        "    \n",
        "    # Images do not need to be transposed. This line also does the reshaping needed.\n",
        "    imgs = data.values[:,1:].reshape(data_rows, img_size, img_size, 1) # img_size * img_size arrays\n",
        "    \n",
        "    labels = keras.utils.to_categorical(data.values[:,0], num_classes) # one-hot encoding vectors\n",
        "    \n",
        "    return imgs/255., labels    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CfcMJtWsFR3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The classes of this balanced dataset are as follows. Index into it based on class label\n",
        "#source data: https://arxiv.org/pdf/1702.05373.pdf\n",
        "#class_mapping = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt' #numbers & letters\n",
        "class_mapping = '0123456789' #numbers only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_McMxZkKhYWs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# View data\n",
        "show_img(train_data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsZKDuJEDKAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Build Model\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "HHEEL-d-F-cj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
        "#above link includes explanation of dropout - used to not overfit and better generalize\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# model.add(keras.layers.Reshape((img_size,img_size,1), input_shape=(784,)))\n",
        "model.add(keras.layers.Conv2D(filters=12, kernel_size=(5,5), strides=2, activation='relu', \n",
        "                              input_shape=(img_size,img_size,1)))\n",
        "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Dropout(.5))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=18, kernel_size=(3,3) , strides=2, activation='relu'))\n",
        "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Dropout(.5))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=24, kernel_size=(2,2), activation='relu'))\n",
        "# model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# model.add(keras.layers.Conv2D(filters=30, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(units=150, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "print(model.input_names)\n",
        "print(model.output_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HPOdKb9DOq9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train Model\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "GgsOAREmTQKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, y = img_label_load(train_data_path)\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AvAtN9khGO78",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_generator = keras.preprocessing.image.ImageDataGenerator(validation_split=.2)\n",
        "\n",
        "training_data_generator = data_generator.flow(X, y, subset='training')\n",
        "validation_data_generator = data_generator.flow(X, y, subset='validation')\n",
        "\n",
        "history = model.fit_generator(training_data_generator, \n",
        "                              steps_per_epoch=500, epochs=10, # can change epochs to 10\n",
        "                              validation_data=validation_data_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsfO4hj0DVGa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "BlXGeSouJSLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data_generator = data_generator.flow(X, y)\n",
        "\n",
        "model.evaluate_generator(test_data_generator)\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cm-n9GDNDlgs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inference â€“ Make Predictions"
      ]
    },
    {
      "metadata": {
        "id": "a6wm8OkzJf6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_img(test_data, 100)\n",
        "\n",
        "#skip for ML serving\n",
        "X_test, y_test = img_label_load(test_data_path) # loads images and orients for model\n",
        "\n",
        "#skip for ML serving\n",
        "def run_prediction(idx):\n",
        "    result = np.argmax(model.predict(X_test[idx:idx+1]))\n",
        "    print('Prediction: ', result, ', Char: ', class_mapping[result])\n",
        "    print('Label: ', test_data.values[idx,0])\n",
        "    show_img(test_data, idx)\n",
        "    \n",
        "#skip for ML serving\n",
        "import random\n",
        "\n",
        "for _ in range(1,10):\n",
        "    idx = random.randint(0, 47-1)\n",
        "    run_prediction(idx)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwxgHLzmDqB1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deploy to ML Cloud Engine"
      ]
    },
    {
      "metadata": {
        "id": "-Daa5d6QDtgH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Prepare Model for Saving"
      ]
    },
    {
      "metadata": {
        "id": "1RWdG_pWGxAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf estimator_model export\n",
        "#model.input_names[0]\n",
        "#!zip -r export.zip export/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJLYB91KK-p5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First, convert Keras Model to TensorFlow Estimator - save estimator model to a directory (this is not saving the keras model)\n",
        "model_input_name = model.input_names[0]\n",
        "estimator_model = keras.estimator.model_to_estimator(keras_model=model, model_dir=\"./estimator_model\")\n",
        "print(model_input_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfZImmT9QZHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EXAMPLE CODE\n",
        "# https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator\n",
        "def input_function(features,labels=None,shuffle=False):\n",
        "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "        x={\"input_node\": features},\n",
        "        y=labels,\n",
        "        shuffle=shuffle,\n",
        "        batch_size = 5,\n",
        "        num_epochs = 1\n",
        "    )\n",
        "    return input_fn\n",
        "  \n",
        "estimator_model.train(input_fn = input_function(X_train,y_train,True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qucLVgidPU4y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dataset_input_fn():\n",
        "    return X,y\n",
        "  \n",
        "#http://tflearn.org/\n",
        "#http://androidkt.com/train-keras-model-with-tensorflow-estimators-and-datasets-api/\n",
        "#if the keras model has already be train we can do it after the fact this way. \n",
        "#Other option to get model artifacts is to save while initial training\n",
        "#train_input = lambda: dataset_input_fn(train_data, None)\n",
        "estimator_model.train(input_fn=dataset_input_fn, steps=10)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6gATbcqPmwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Next, export the TensorFlow Estimator to SavedModel\n",
        "\n",
        "\n",
        "#defines the format for the input required during serving prediction[]\n",
        "def serving_input_receiver_fn():\n",
        "    input_ph = tf.placeholder(tf.string, shape=[None], name='image_binary')#name of this tensor is used when serving input during prediction\n",
        "#https://www.tensorflow.org/api_docs/python/tf/map_fn\n",
        "#https://www.learnpython.org/en/Partial_functions\n",
        "#https://www.tensorflow.org/api_docs/python/tf/image/decode_image\n",
        "    images = tf.map_fn(partial(tf.image.decode_image, channels=1), input_ph, dtype=tf.uint8) #specifies how inputs should be unpacked\n",
        "    images = tf.cast(images, tf.float32) / 255.\n",
        "    images.set_shape([None, 28, 28, 1]) #(batch_size, x_dim, y_dim, z or image channels)\n",
        "\n",
        "    #images\n",
        "    # the first key is the name of first layer of the (keras) model. \n",
        "    # The second key is the name of the key that will be passed in the prediction request\n",
        "    return tf.estimator.export.ServingInputReceiver({model_input_name: images}, {'bytes': input_ph})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAI1jgmrPr0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "export_path = estimator_model.export_savedmodel('./export', serving_input_receiver_fn=serving_input_receiver_fn)\n",
        "export_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sR6zmoyDyLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Upload model to existing GCS bucket"
      ]
    },
    {
      "metadata": {
        "id": "If3WFjIOP2uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebooks/io.ipynb#scrollTo=xM70QWdxeE7q\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Existing bucket name\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'mltestproject'\n",
        "\n",
        "# Copy the model directory to our new bucket.\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!gsutil cp -r export/1550605828/. gs://{bucket_name}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmZg4NYmD4N2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Upload GOOGLE_APPLICATION_CREDENTIALS"
      ]
    },
    {
      "metadata": {
        "id": "EqNNjyGpmjJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Upload GOOGLE_APPLICATION_CREDENTIALS json file from local computer and save to this notebook\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WXejMwPsD7sm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Set GOOGLE_APPLICATION_CREDENTIALS environment variable"
      ]
    },
    {
      "metadata": {
        "id": "CieYaLyymZwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'MLTest-1b56c585b43f.json' #INSERT YOUR CREDENTIALS FILENAME HERE!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_CU43I9VEAXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Request online prediction from deployed model"
      ]
    },
    {
      "metadata": {
        "id": "OMzehCPhR0Zi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "#function to create base64 encoded data for online prediction from image array test data\n",
        "def exportB64Str(row_num, data=test_data):\n",
        "  buffered = BytesIO()\n",
        " \n",
        "  #create json test input for online prediction\n",
        "  array = data.values[row_num,1:].reshape(28, 28)\n",
        "\n",
        "  img = Image.fromarray(array.astype(np.uint8))\n",
        "\n",
        "  img.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue())\n",
        "  #print(img_str)\n",
        "  #strip leading and trailing format characters\n",
        "  img_str = str(img_str).replace(\"\\\"\", \"\").replace(\"b'\", \"\").replace(\"'\", \"\") \n",
        "  return img_str\n",
        "# show_img(test_data, row_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gGxJyLIl9nK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exportB64Str(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lsef29HsRUGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#mnistTest1\n",
        "#Need tensorflow 1.12 for google cloud ml engine\n",
        "#Setup online cloud model\n",
        "#https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions\n",
        "\n",
        "import googleapiclient \n",
        "from googleapiclient import discovery\n",
        "from googleapiclient import errors\n",
        "\n",
        "\n",
        "#row_num = 101 #0\n",
        "#row_num = 107 #1 or index 2\n",
        "#row_num = 109 #4\n",
        "#row_num = 0 #7\n",
        "row_num = 30 #3\n",
        "#row_num = 100 #6\n",
        "  \n",
        "# Create the ML Engine service object.\n",
        "# To authenticate set the environment variable\n",
        "# GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
        "#name = 'projects/{}/models/{}'.format(Project ID, 'MpgModel')\n",
        "service = googleapiclient.discovery.build('ml', 'v1')\n",
        "name = 'projects/{}/models/{}'.format('mltest-229502', 'MpgModel')\n",
        "\n",
        "#if version is not None:\n",
        "name += '/versions/{}'.format('mnistTest1')\n",
        "\n",
        "response = service.projects().predict(\n",
        "    name=name,    \n",
        "    #body= {\"instances\":[{\"bytes\": {\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3klEQVR4nGNgGMLA+vhqUxxSvH4fzubcb+TBKpm0wpuXwffvfg4sctIfGhgYGBhWX2TDIln0UY6BgcH7ewKauI8CAwPDhrsMDAxy1+/ywUSZGBgYGBhYFmYzMDC8Z2Fj8Dz6xfYTqkbmWw8YGBi8//lGPrmjgmFd4h83BgaBp//+nZXAdAvTwbfBDNon/t0Rx+ZFtU+/rz5cteuHHzZJBmmPSg0G+ed3Ma2EA/Nv+GQ1ruOTlbv+0R23LPfmz5q4ZTkvfI3CLcu+63c+M05Zprzfh5lwaw58wIJbkggAALefQem8NL8aAAAAAElFTkSuQmCC\"}}]}\n",
        "     #body= {\"instances\":[{\"bytes\": {\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxklEQVR4nNXQoRMBQRQG8M9FV++q7Cp/hEwlC4pRiWTVqEQum5HushmKIxIJEvF97wRmBG+L5m3Ynf3N92b3Af9YYS9VKnXZMHBFea17+XPpvffAu607292t4He/k/VJBUCUCg0EAPiZcuOwQSaUum1VKnUS2ljcU3g59a3PABiclEqt2RpUhpkwcbwJCGfK9vvsfWmU50dXckRtupqOKdeSbdGBmjly8ztlWTTAj2PmPNvTGwmFi8BuOeVj4xgc0Er6Lvqhnm7tXZhILmyQAAAAAElFTkSuQmCC\"}}]}\n",
        "    body= {\"instances\":[{\"bytes\": {\"b64\": exportB64Str(row_num, test_data)}}]}    \n",
        "        \n",
        "   # body= {\"instances\":[{\"bytes\": {\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7ElEQVR4nGNgGBmAEYkpySAv9uvIZ0xFvKF7L/z79+/fv2enw9Fkyt58/vxmZaQLP7/25Bd/VrIiyTm8ftwaKwrjsUz+2Y2Qq3/aI4liUOdvczj77m0WOFuixEaLQfxBL1zAJIMZymKa9uT3/7+zOCacxnQx28LnTuxuXk8Dir9gSvb9c2FgYGBoSSneAjUJydEFWXsZGBgYvjMGnMWQDH80/z/EeOtDGJIMn38yMDAwMBxR27sf6mWE3IdHEFpOv+Afhnu8PgZwMjCwFP0wxnQrA6Pb/edHjlx86YgQQZbm57bl/bD3PRaN9AMAYiZNYC9hK9EAAAAASUVORK5CYII=\"}}]}\n",
        ").execute()\n",
        "\n",
        "if 'error' in response:\n",
        "    raise RuntimeError(response['error'])\n",
        "  \n",
        "response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWv6ez7v-E25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = exportB64Str(30, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZycCm_A1RfvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#find prediction from response\n",
        "result = np.argmax(response['predictions'][0]['dense_1'])\n",
        "class_mapping[result]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dZjgNWCIRnP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Example saving a trained model to a file and loading a trained model from a file to perform predictions/inference"
      ]
    },
    {
      "metadata": {
        "id": "-DttPXRvZdrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def export_png(row_num, data=test_data):\n",
        "    #array = np.transpose(data.values[row_num,1:].reshape(28, 28), axes=[1,0])\n",
        "    array = data.values[row_num,1:].reshape(28, 28)\n",
        "    img = Image.fromarray(array.astype(np.uint8))\n",
        "    filename = 'class_' + str(data.values[row_num,0]) + '_label_' + str(class_mapping[data.values[row_num,0]]) + '.png'\n",
        "    img.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKKlPQ5K5LM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl, utils\n",
        "row_num = 30 #3\n",
        "\n",
        "# img = load_img('class_3_label_3.png')\n",
        "# img.thumbnail((28, 28))\n",
        "# test_x = img_to_array(img) \n",
        "# test_x = test_x[:,:,0:1] #select only one channel\n",
        "# test_x1 = test_x.copy(order='C')\n",
        "\n",
        "# img_str = base64.b64encode(test_x1)\n",
        "\n",
        "# print(img_str)\n",
        "#img_str = str(img_str).replace(\"\\\"\", \"\").replace(\"b'\", \"\").replace(\"'\", \"\") \n",
        "\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "    metagraph = tf.saved_model.loader.load(sess, [tag_constants.SERVING], \"export/1551073325\")\n",
        "    graph = tf.get_default_graph()\n",
        "    #inputs_mapping = dict(metagraph.signature_def['serving_default'].inputs)\n",
        "    #print(inputs_mapping)\n",
        "    \n",
        "    #outputs_mapping = dict(metagraph.signature_def['serving_default'].outputs)\n",
        "    #print(outputs_mapping)\n",
        "#     for op in graph..get_operations():\n",
        "#       print(op.name)\n",
        "    x = graph.get_tensor_by_name(\"image_binary:0\") #input layer name maps to tensor in the graph\n",
        "    model = graph.get_tensor_by_name(\"dense_1/Softmax:0\") #output layer name  \n",
        "   \n",
        "    print(sess.run(model, feed_dict={x: [img_str]}))\n",
        "    #print(sess.run(model, feed_dict={x: [str(exportB64Str(row_num, test_data))]}))\n",
        "#    print(sess.run(model, feed_dict={x: [{\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxklEQVR4nNXQoRMBQRQG8M9FV++q7Cp/hEwlC4pRiWTVqEQum5HushmKIxIJEvF97wRmBG+L5m3Ynf3N92b3Af9YYS9VKnXZMHBFea17+XPpvffAu607292t4He/k/VJBUCUCg0EAPiZcuOwQSaUum1VKnUS2ljcU3g59a3PABiclEqt2RpUhpkwcbwJCGfK9vvsfWmU50dXckRtupqOKdeSbdGBmjly8ztlWTTAj2PmPNvTGwmFi8BuOeVj4xgc0Er6Lvqhnm7tXZhILmyQAAAAAElFTkSuQmCC\"}]}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPvW0nYMUTmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import predictor\n",
        "\n",
        "predict_fn = predictor.from_saved_model('export/1551073325')\n",
        "#predictions = predict_fn({'bytes': [b'iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxElEQVR4nN2QIRMBURSFD3FVr8rUlWXZVrJqVCJZ3VGJVjYj7eY3I1mViLpBueeuYGY9M/YHcNL95ptzZ+4F/i1mZ3ulcsw8dLk2Xw4KSOTmu3IrjIHqCzqVwwFoe4WtPPbFTBkCUx7fbN9rlBa1VDl94TpnAKdpW6lQznUAaGXcwG3eE6VSfQDmxEvdkZFQKOGVMwALysfRQaa0PXPW1Jg5Nfr8QjMcAZhQVpaSeviSQKnU2zcFoBtT+o0SCQw7peqX8wRrml8mRYL5pwAAAABJRU5ErkJggg==']}) #ERROR - Unable to decode bytes as JPEG, PNG, GIF, or BMP\n",
        "#predictions = predict_fn({'bytes': test_data.values[30,1:]}) #ERROR - Unable to get element as bytes\n",
        "#predictions = predict_fn({'bytes': exportB64Str(30, test_data)}) #ERROR - Cannot feed value of shape () for Tensor 'image_binary:0', which has shape '(?,)'\n",
        "#predictions = predict_fn({'bytes': [exportB64Str(30, test_data)]}) #ERROR - assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\n",
        "#predictions = predict_fn({'bytes': [test_data.values[30,1:]]}) #ERROR - Cannot feed value of shape (1, 784) for Tensor 'image_binary:0', which has shape '(?,)'\n",
        "\n",
        "predictions\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttA-MndPZ28D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('my_model_tf_1_1_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZibIvKEAdPas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "#https://www.kaggle.com/lgmoneda/from-image-files-to-numpy-arrays\n",
        "#https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
        "#https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html\n",
        "#from keras.models import load_model\n",
        "#model.save('my_model.h5')\n",
        "\n",
        "##Process png to proper shape numpy array\n",
        "img = load_img('class_3_label_3.png')\n",
        "img.thumbnail((28, 28))\n",
        "test_x = img_to_array(img) \n",
        "test_x = test_x[:,:,0:1] #select only one channel\n",
        "#   dat = img_file.read()\n",
        "  #tdat = np.frombuffer(dat, dtype=np.byte)/255\n",
        "  #imgs = tdat.reshape(1, img_size, img_size, 1) # img_size * img_size arrays\n",
        "print(test_x.shape)\n",
        "\n",
        "#\n",
        "#print(tdat)\n",
        "\n",
        "model2 =  tf.keras.models.load_model('my_model_tf_1_1_1.h5')\n",
        "#predictions = model2.predict(X_test[30:31])\n",
        "predictions = model2.predict([[test_x]])\n",
        "\n",
        "result = np.argmax(predictions)\n",
        "class_mapping[result]\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}