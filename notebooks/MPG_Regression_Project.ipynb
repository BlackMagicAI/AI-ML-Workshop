{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MPG_Regression_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtedder/AI-ML-Workshop/blob/master/notebooks/MPG_Regression_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qyEYI6on6kt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MPG Regression - Predict Fuel Efficiency Keras Project\n",
        "\n",
        "[Ref Docs 1](https://www.tensorflow.org/tutorials/keras/basic_regression)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Dz5ROrVSNuTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ]
    },
    {
      "metadata": {
        "id": "odmx0Ak4NvhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Regression example - https://www.tensorflow.org/tutorials/keras/basic_regression\n",
        "#https://towardsdatascience.com/getting-data-into-tensorflow-estimator-models-3432f404a8da\n",
        "#Ref: https://www.tensorflow.org/api_docs/python/tf\n",
        "#Data - How to get it\n",
        "import tensorflow as tf\n",
        "sess = tf.Session()\n",
        "from keras import backend as K\n",
        "K.set_session(sess)\n",
        "K.set_learning_phase(0) # all new operations will be in test mode from now on\n",
        "\n",
        "import os\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "#from tensorflow import keras\n",
        "\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl, utils\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "#imports for online predictions\n",
        "import googleapiclient \n",
        "from googleapiclient import discovery\n",
        "from googleapiclient import errors\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "#from tensorflow.keras import layers\n",
        "# Import the `pyplot` module\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqMKcyWFN7Rj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Version Info"
      ]
    },
    {
      "metadata": {
        "id": "jCuxrtEeOATj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python --version\n",
        "# print(\"Tensorflow version\" + tf.__version__)\n",
        "##VIEW DATASET\n",
        "# dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "# !cat dataset_path\n",
        "# %cd datasets/\n",
        "# !ls -al\n",
        "# !cat auto-mpg.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFOnZ_Gj6B_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "pWQ-t7fR6X_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MPG regression data\n",
        "#Downloads a file from a URL to /root/.keras/datasets/auto-mpg.data if it not already in the cache. Store path to file in dataset_path variable - https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n",
        "dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "#Create Column names list because file data does not have a header row\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model_Year', 'Origin']\n",
        "#Read downloaded csv file and convert to dataframe - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t', sep=\" \", skipinitialspace=True)\n",
        "\n",
        "#Make a copy of this object’s indices and data - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html#pandas.DataFrame.copy\n",
        "dataset = raw_dataset.copy()\n",
        "\n",
        "#Return the last n row(s) default n = 5 - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html#pandas.DataFrame.tail\n",
        "#dataset.tail()\n",
        "dataset.head(40) #NaN value on line 32 col. 4\n",
        "\n",
        "#Detect missing values & Return the sum of the values for the requested axis - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Panel.isna.html#pandas.Panel.isna\n",
        "#http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html#pandas.DataFrame.sum\n",
        "dataset.isna().sum()\n",
        "\n",
        "#Remove missing values NaN etc...- http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "#Convert categorical Origin column to one-hot - https://developers.google.com/machine-learning/glossary/#one-hot_encoding\n",
        "#https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/: \"In fact, using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\"\n",
        "#Return item and drop from frame - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pop.html#pandas.DataFrame.pop\n",
        "origin = dataset.pop('Origin')\n",
        "\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ik4MZya4OOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Workspace cell\n",
        "#dataset.head(40)\n",
        "#dataset.size\n",
        "# dataset = dataset.dropna()\n",
        "# dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfDogsA2OSGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "m-cUxjkaOA8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now split the data into a train and a test set\n",
        "#Return a random sample of items from an axis of object - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html#pandas.DataFrame.sample\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "#Drop specified labels from rows or columns with the given indecies (index)- http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "#Inspect the data using matplotlib - https://matplotlib.org/\n",
        "#http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
        "#https://matplotlib.org/api/mlab_api.html?highlight=kde#matplotlib.mlab.GaussianKDE\n",
        "# l = plt.mlab.GaussianKDE(train_dataset[\"MPG\"])\n",
        "# plt.show()\n",
        "\n",
        "#Or use dataframe plot function to get Kdensity plot - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html\n",
        "#https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0\n",
        "#train_dataset[\"MPG\"].plot(use_index=False, kind=\"kde\")\n",
        "\n",
        "\n",
        "#Look at the overall statistics\n",
        "#Generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values\n",
        "#https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe\n",
        "train_stats = train_dataset.describe()\n",
        "# print(train_stats)\n",
        "\n",
        "#Return item and drop from frame - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pop.html#pandas.DataFrame.pop\n",
        "train_stats.pop(\"MPG\")\n",
        "\n",
        "#Transpose index and columns (for display purposes - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose\n",
        "train_stats = train_stats.transpose()\n",
        "\n",
        "print(train_stats)\n",
        "\n",
        "#get labels from the features train dataset - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pop.html#pandas.DataFrame.pop\n",
        "train_labels = train_dataset.pop('MPG')\n",
        "\n",
        "#get labels from the features test dataset\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "\n",
        "#normalize the train and test data to bring values to the same scale using standard score calculation - https://en.wikipedia.org/wiki/Standard_score\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "#Pandas Dataframe\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "\n",
        "normed_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TX1u8P0F5xQh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Build Model\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "tIkHOidvbb2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#MPG data model\n",
        "EPOCHS = 100\n",
        "\n",
        "# model = keras.models.Sequential()\n",
        "# model.add(Dense(64, activation=tf.nn.relu, input_shape=(len(train_dataset.keys()),), name='feature'))\n",
        "# model.add(Dense(64, activation=tf.nn.relu, name='midLayer'))\n",
        "# model.add(Dense(1, name='outLayer'))\n",
        "\n",
        "# model = keras.models.Sequential()\n",
        "# model.add(keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(len(normed_train_data.keys()),), name='feature'))\n",
        "# model.add(keras.layers.Dense(64, activation=tf.nn.relu, name='midLayer'))\n",
        "# model.add(keras.layers.Dense(1, name='outLayer'))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation=tf.nn.relu, input_dim=(len(normed_train_data.keys()))))\n",
        "# model.add(Activation('tanh'))\n",
        "model.add(Dense(64, activation=tf.nn.relu, name='midLayer'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# model = keras.models.Sequential()\n",
        "# model.add(keras.layers.Dense(64, activation=tf.nn.relu, input_dim=(len(normed_train_data.keys()))))\n",
        "# model.add(keras.layers.Dense(64, activation=tf.nn.relu, name='midLayer'))\n",
        "# model.add(keras.layers.Dense(1))\n",
        "\n",
        "\n",
        "# model.add(Activation('sigmoid'))\n",
        "# sgd = SGD(lr=0.1)\n",
        "#Define an Optimizer that implements the RMSProp algorithm with a learning rate (step size) of .001 - https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
        "#http://www.cs.toronto.edu/%7Etijmen/csc321/slides/lecture_slides_lec6.pdf\n",
        "#Specifies algorithm to help with convergence to the minimum error\n",
        "#https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a\n",
        "#https://engmrk.com/rmsprop/?utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com\n",
        "optimizer = tf.train.RMSPropOptimizer(0.001)\n",
        "\n",
        "#Compile Configures the model for training - https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#compile\n",
        "#Use 'mae' and 'mse' list of metrics to be evaluated by the model during training and testing by calculating these they can be used to track model accuracy\n",
        "#Use 'mse' to compute loss - https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss\n",
        "# model.compile(loss='mse',\n",
        "#                 optimizer=optimizer,\n",
        "#                 metrics=['mae', 'mse', 'accuracy'])\n",
        "model.compile(loss='mse',\n",
        "                optimizer=optimizer, metrics=['mae', 'mse']) #We'll use the mean square error, a standard loss for regression problems. https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "#print a simple description of the model - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRipI30H51gN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train Model\n",
        "Ref:"
      ]
    },
    {
      "metadata": {
        "id": "6wHbdx4mvIz7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Not needed for Cloud ML Serving\n",
        "#Train the model\n",
        "#Test the untrained model using a small batch of 10 samples to test for errors\n",
        "#by calling the predict function which generates output predictions for the input samples - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#predict\n",
        "#example_batch = normed_train_data[:10]\n",
        "#example_result = model.predict(example_batch)\n",
        "#example_result\n",
        "#If it runs without errors, start training the model\n",
        "EPOCHS = 1000\n",
        "\n",
        "# train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "#     x=normed_train_data,\n",
        "#     y=train_labels,\n",
        "#     batch_size=100,\n",
        "#     num_epochs=EPOCHS,\n",
        "#     shuffle=True,\n",
        "#     queue_capacity=1000,\n",
        "#     num_threads=1\n",
        "# )\n",
        "\n",
        "\n",
        "#tf.keras.backend.clear_session() #https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session\n",
        "\n",
        "#Train using fit which Trains the model for a fixed number of epochs (iterations on a dataset) - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit\n",
        "#validation_split of .2. Fraction of the training data to be used as validation data\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0)\n",
        "\n",
        "#Alternate training using EarlyStopping callback - https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "# The patience parameter is the amount of epochs to check for improvement.\n",
        "# Early stopping is a useful technique to prevent overfitting.\n",
        "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
        "\n",
        "# history = model.fit(\n",
        "#     normed_train_data, train_labels,\n",
        "#     epochs=EPOCHS,\n",
        "#     validation_split = 0.2, verbose=0, callbacks=[early_stop])\n",
        "\n",
        "#Visualize the model's training progress\n",
        "#History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable)\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-h9GGIr54o_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "3gbtrV805Z7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Not needed for Cloud ML Serving\n",
        "#Is this model good? Visualize model performance\n",
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Abs Error [MPG]')\n",
        "\n",
        "plt.plot(hist['epoch'], hist['mean_absolute_error'], label='Train Error')\n",
        "  \n",
        "plt.plot(hist['epoch'], hist['val_mean_absolute_error'], label = 'Val Error')\n",
        "plt.legend()\n",
        "plt.ylim([0,5])\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "         label='Train Error')\n",
        "plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "         label = 'Val Error')\n",
        "plt.legend()\n",
        "plt.ylim([0,20])\n",
        "\n",
        "#Test model using the test data and evaluate\n",
        "#Returns the loss value & metrics values for the model in test mode - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#evaluate\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJLmhznxAGGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inference – Make Predictions"
      ]
    },
    {
      "metadata": {
        "id": "U1BdBEPFAFST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Not needed for Cloud ML Serving\n",
        "#Use test data to make predictions on trained model\n",
        "#Predict Generates output predictions for the input sample - https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#predict\n",
        "#Then flatten numpy array result - https://www.tutorialspoint.com/numpy/numpy_ndarray_flatten.htm\n",
        "results_predictions = model.predict(normed_test_data)\n",
        "test_predictions = results_predictions.flatten()\n",
        "\n",
        "#Plot the results\n",
        "plt.figure()\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "\n",
        "#Plot error Histogram\n",
        "plt.figure()\n",
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_N8jjOaVaxOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deploy to ML Cloud Engine\n",
        "[Tensorflow serving Ref](https://www.tensorflow.org/tfx/guide/serving)\n",
        "\n",
        "[Preparing Models for the cloud](https://towardsdatascience.com/freezing-a-keras-model-c2e26cb84a38)"
      ]
    },
    {
      "metadata": {
        "id": "qPDHionCaOdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8NB1Va9szxG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Prepare Model for Saving"
      ]
    },
    {
      "metadata": {
        "id": "1lvKB_e3v_Dm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "model_version = \"1\" #Change this to export different model versions, i.e. 2, ..., 7\n",
        "\n",
        "#import tensorflow as tf\n",
        "#setting values for the sake of saving the model in the proper format\n",
        "#http://amygdala.github.io/ml/tensorflow/cloud_ml_engine/2018/01/26/tf.html\n",
        "x = model.input\n",
        "y = model.output\n",
        "\n",
        "# receiver_tensors = {\n",
        "#     'Cylinders' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Displacement' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Horsepower' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Weight' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Acceleration' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Model_Year' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'USA' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Europe' : tf.placeholder(shape=[None,1], dtype=tf.float32),\n",
        "#     'Japan' : tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
        "#   }\n",
        "\n",
        "# receiver_tensors = {\n",
        "#     'Cylinders' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Displacement' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Horsepower' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Weight' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Acceleration' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Model_Year' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'USA' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Europe' : tf.placeholder(shape=[1,1], dtype=tf.float32),\n",
        "#     'Japan' : tf.placeholder(shape=[1,1], dtype=tf.float32)\n",
        "#   }\n",
        "\n",
        "#Start tried this!\n",
        "# https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/census/tensorflowcore/trainer/task.ipynb\n",
        "# https://github.com/GoogleCloudPlatform/cloudml-samples/issues/67\n",
        "# INPUT_COLUMNS = normed_train_data.columns\n",
        "# def input_fn():\n",
        "#   \"\"\"Build the serving inputs.\"\"\"\n",
        "#   inputs = {}\n",
        "#   for feat in INPUT_COLUMNS:\n",
        "#     inputs[feat] = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
        "  \n",
        "#   return inputs\n",
        "\n",
        "# inputs_dict = input_fn()\n",
        "\n",
        "# inputs_info = {\n",
        "#         name: tf.saved_model.utils.build_tensor_info(tensor)\n",
        "#         for name, tensor in inputs_dict.items()\n",
        "#     }\n",
        "\n",
        "# signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
        "#       inputs=inputs_info,\n",
        "#       outputs={\"prediction\":tf.saved_model.utils.build_tensor_info(tf.placeholder(shape=[None,1], dtype=tf.float32))},\n",
        "#       method_name=signature_constants.PREDICT_METHOD_NAME\n",
        "#   )\n",
        "#End tried this!\n",
        "\n",
        "# signature_def = tf.saved_model.signature_def_utils.regression_signature_def(\n",
        "#       inputs_info,\n",
        "#       {\"prediction\":tf.saved_model.utils.build_tensor_info(tf.placeholder(shape=[None,1], dtype=tf.float32))}\n",
        "# #       method_name=signature_constants.PREDICT_METHOD_NAME\n",
        "#   )\n",
        "\n",
        "# print ('Results of Model', model.predict_proba(normed_train_data))\n",
        "# print ('Results of Model', model.predict_proba(x_df))\n",
        "# tensor_info_x = utils.build_tensor_info(x)\n",
        "# tensor_info_y = utils.build_tensor_info(y)\n",
        "\n",
        "#prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def(receiver_tensors, {\"prediction\":y}) #for MPG model\n",
        "prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def({\"inputs\":x}, {\"prediction\":y}) #for MPG model - use this one\n",
        "\n",
        "# valid_prediction_signature = tf.saved_model.signature_def_utils.is_valid_signature(prediction_signature)\n",
        "# if(valid_prediction_signature == False):\n",
        "#     raise ValueError(\"Error: Prediction signature not valid!\")\n",
        "\n",
        "builder = saved_model_builder.SavedModelBuilder('./'+ model_version)\n",
        "#legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "#legacy_init_op = tf.group(tf.global_variables_initializer(), name='legacy_init_op')\n",
        "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
        "\n",
        "# ex.1\n",
        "# init_local = tf.global_variables_initializer() #tf.local_variables_initializer()\n",
        "# init_tables = tf.tables_initializer()\n",
        "# legacy_init_op = tf.group(init_local, init_tables)\n",
        "\n",
        "# Add the meta_graph and the variables to the builder\n",
        "builder.add_meta_graph_and_variables(\n",
        "      sess, [tag_constants.SERVING],\n",
        "      signature_def_map={\n",
        "           signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature,\n",
        "#          signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:signature_def, #ex.1\n",
        "      },\n",
        "      #main_op=tf.tables_initializer())\n",
        "      legacy_init_op=legacy_init_op)\n",
        "\n",
        "# save the graph\n",
        "builder.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gIfhbnq2Xmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Save trained model to OS drive (optional not required for serving)"
      ]
    },
    {
      "metadata": {
        "id": "FdbgZW8xRF3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Export/Save trained model\n",
        "#https://cloud.google.com/ml-engine/docs/scikit/deploying-models\n",
        "#https://www.tensorflow.org/guide/saved_model#performing_the_export\n",
        "#https://www.tensorflow.org/tutorials/keras/save_and_restore_models\n",
        "#https://medium.com/tensorflow/training-and-serving-ml-models-with-tf-keras-fd975cc0fa27\n",
        "#https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save\n",
        "#https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py#L100\n",
        "#https://towardsdatascience.com/deploy-tensorflow-models-9813b5a705d5\n",
        "\n",
        "#graph1 = tf.Graph()\n",
        "tf.keras.backend.set_learning_phase(0) # Ignore dropout at inference\n",
        "tf.keras.backend.clear_session() #https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session\n",
        "\n",
        "cwd = os.getcwd()\n",
        "export_path = os.path.join(cwd, 'testmodel1')\n",
        "\n",
        "#https://towardsdatascience.com/deploy-tensorflow-models-9813b5a705d5\n",
        "#tensor_info_output = tf.saved_model.utils.build_tensor_info(model.outputs[0])\n",
        "out = tf.placeholder(shape=model.outputs[0].get_shape(), dtype=model.outputs[0].dtype, name='myresult')\n",
        "#out = tf.estimator.export.ClassificationOutput(classes=tf.placeholder(tf.strings, name='outresult'))\n",
        "\n",
        "#Keras save model method #2 - using the simple_save function \n",
        "with tf.keras.backend.get_session() as sess:\n",
        "  tf.saved_model.simple_save(\n",
        "      sess,\n",
        "      export_path,      \n",
        "      inputs= json_serving_input_fn().features,\n",
        "      outputs={'result':out})  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POCuYD0S0zE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh\n",
        "from google.colab import files\n",
        "files.download('testmodel1/saved_model.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V5G9bhPvxbx1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Upload model to existing GCS bucket"
      ]
    },
    {
      "metadata": {
        "id": "BZH6hihDxZoL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebooks/io.ipynb#scrollTo=xM70QWdxeE7q\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Existing bucket name\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = '#INSERT YOUR BUCKET NAME HERE!!'\n",
        "\n",
        "# Copy the model directory to our new bucket.\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!gsutil cp -r INSERT MODEL DIRECTORY NAME HERE/. gs://{bucket_name}/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uja9PDJmLep7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Upload GOOGLE_APPLICATION_CREDENTIALS json file"
      ]
    },
    {
      "metadata": {
        "id": "4KzEKMq5Kr7U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Upload GOOGLE_APPLICATION_CREDENTIALS json file from local computer and save to this notebook\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fzLz4zKEWM2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Create GOOGLE_APPLICATION_CREDENTIALS environment variable"
      ]
    },
    {
      "metadata": {
        "id": "q5Dmf2TZWTkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#set GOOGLE_APPLICATION_CREDENTIALS environment variable\n",
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'INSERT YOUR CREDENTIALS FILENAME HERE!!'\n",
        "version=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gK2ihAu652H_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Request online prediction from deployed model"
      ]
    },
    {
      "metadata": {
        "id": "whIjYXDs5-tw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Setup online cloud model\n",
        "#https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions\n",
        "\n",
        "#Setup online cloud model\n",
        "#https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#requesting_predictions\n",
        "#https://cloud.google.com/ml-engine/docs/v1/predict-request\n",
        "# https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library\n",
        "#https://www.raspberrypi.org/magpi/tensorflow-ai-raspberry-pi/\n",
        "#https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.98614&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
        "#https://stackoverflow.com/questions/45705070/how-to-load-and-use-a-saved-model-on-tensorflow\n",
        "Project_ID = 'mltest-229502'\n",
        "MODEL_NAME = 'MpgModel'\n",
        "MODEL_VERSION_NAME = 'MpgModel2'\n",
        "\n",
        "# Create the ML Engine service object.\n",
        "# To authenticate set the environment variable\n",
        "# GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
        "#name = 'projects/{}/models/{}'.format(Project ID, 'MpgModel')\n",
        "service = googleapiclient.discovery.build('ml', 'v1')\n",
        "name = 'projects/{}/models/{}'.format(Project_ID,  MODEL_NAME)\n",
        "\n",
        "#if version is not None:\n",
        "name += '/versions/{}'.format(MODEL_VERSION_NAME)\n",
        "\n",
        "##Test data taken from first row (index 9) of normed_test_data\n",
        "response = service.projects().predict(\n",
        "    name=name,\n",
        "    body={\"instances\": [{\"inputs\": [1.483887,1.865988,2.234620,1.018782,-2.530891,-1.604642,0.774676,-0.465148,-0.495225]}]} #this WORKS! with the mpg model\n",
        ").execute()\n",
        "\n",
        "# if 'error' in response:\n",
        "#     raise RuntimeError(response['error'])\n",
        "\n",
        "#expect [16.888962] for inputs Cylinders,Displacement,Horsepower,Weight,Acceleration,Model_Year,USA,Europe,Japan\n",
        "#                              [1.483887,1.865988,2.234620,1.018782,-2.530891,-1.604642,0.774676,-0.465148,-0.495225]\n",
        "  \n",
        "response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YsBtPZT0JpMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Loading and running a prediction from a saved file"
      ]
    },
    {
      "metadata": {
        "id": "vRcn4qrEJltx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "    tf.saved_model.loader.load(sess, [tag_constants.SERVING], \"1\")\n",
        "    graph = tf.get_default_graph()\n",
        "    x = graph.get_tensor_by_name(\"dense_1_input:0\") #input layer name maps to tensor in the graph\n",
        "    model = graph.get_tensor_by_name(\"dense_2/BiasAdd:0\") #output layer name   \n",
        "    print(sess.run(model, feed_dict={\"dense_1_input:0\": [[1.483887,1.865988,2.234620,1.018782,-2.530891,-1.604642,0.774676,-0.465148,-0.495225]]}))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}